{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Practica 4\n\n\n\nEl objetivo final de esta práctica es el de implementar la función que permitirá extraer las características para entrenar una red neuronal fully connected.\n\nVeremos a lo largo del cuaderno que extraeremos características a partir del espectrograma lineal y otras a partir del espectrograma mel. \n\nEn la primera parte de la práctica implementaremos algunas de estas características, mientras que otras las extraeremos empleando la librería [`librosa`](https://librosa.org/)\n\nA lo largo de los ejercicios de esta sesión emplearemos el fichero de audio `nine.wav`\n\n## Preparativos\n\nComenzaremos cargando dicho audio y seleccionando el fragmento de voz tal y como hicimos al final de la practica anterior con la funcion `detect_speech`:","metadata":{}},{"cell_type":"code","source":"import librosa\nimport numpy as np\nfrom utils import detect_speech\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio, display # Escuchar audio\nimport pytest\nimport UPVlog","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T12:44:11.497077Z","iopub.status.idle":"2025-06-13T12:44:11.497480Z","shell.execute_reply.started":"2025-06-13T12:44:11.497286Z","shell.execute_reply":"2025-06-13T12:44:11.497303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Read the audio file\nnine, fs = librosa.load('nine.wav', sr = None, mono = False)  #mantenemos la frec. original\n\nnine_mask = detect_speech(nine, fs) #guarda aqui el resultado de detect_speech, true cuando haya voz\n\nnine_mask = np.where(nine_mask.astype(bool))[0]\n\nnine_trim = nine[nine_mask] #guarda aqui el audio recortado, que queda solo cn los true de antes, se queda solo cn la voz\n\nt = np.arange(nine.shape[0]) / fs # vector de tiempos para representar nine\n\nt_trim = np.arange(len(nine_trim)) / fs #Vector de tiempos para respresentar nine_trim","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Comprobación \nmy_logger.test(\"lectura y preprocesado audio\")\nassert len(nine) == 16000, \"lee el ficheo nine.wav\"\nassert len(nine_trim) == 8880, \"Recorta los silencions con detect_speech\"\nassert t_trim.max() == pytest.approx(0.554, 1e-2)\nmy_logger.success(\"lectura y preprocesado audio\",2.0)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Representaremos el audio original y recortado:","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2,1)\n\naxes[0].plot(t, nine)\naxes[0].set_title('Nueve original')\naxes[0].set_xlabel('time')\n\naxes[1].plot(t_trim, nine_trim)\naxes[1].set_title('Nueve')\naxes[1].set_xlabel('time')\n\ndisplay(Audio(nine_trim, rate = fs))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"En lo que resta de práctica emplearemos como audio de muestra el audio recortado: `nine_trim`\n\n\nLas primeras características que emplearemos se basan en el espectrograma lineal. Por tanto en primer lugar calcularemos el modulo del espectrograma con los siguientes parámetros:abs\n* Longitud de la trama 32ms.\n* Solape 50%\n* Ventana Hamming\n* Numero de puntos de la FFT 512\n\nUse la funciones de `librosa.stft` tal y como hizo en el ejercicio 1 de la práctica 3.\n","metadata":{}},{"cell_type":"code","source":"window = \"hamming\"\nn_fft = 512\ntham = 0.032\nwin_length = int(tham * fs)\nhop_length = int(win_length * 0.5)\n\nS = librosa.stft(nine_trim, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window) # espectrograma calculado con librosa.stft (esta matriz es compleja)\nabsS = np.abs(S) # aqui guardaremos el valor absoluto de S","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmy_logger.test(\"generar espectrograma\")\n\n\nassert absS.shape == (257,35), \"repasa win_length y hop_length\"\nassert absS.dtype == np.dtype('float32'), \"Toma el valor absoluto de S\"\nassert np.abs(S[2,2]) == pytest.approx(0.324, abs = 1e-3)\n\n\nfig, ax = plt.subplots()\nlibrosa.display.specshow(np.abs(S),sr=fs, hop_length=hop_length, x_axis='time', y_axis='linear', ax= ax)\n_ = ax.set_title('Espectrograma nine')\nmy_logger.success(\"generar espectrograma\",2.0)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ejercicio 1: Calculo del centroide espectral\nUna vez calculado el espectrograma vamos a realizar una función para el cálculo del centroide espectral. El resultado debería ser identico al que obtenemos\n con la función: [`librosa.feature.spectral_centroid`](https://librosa.org/doc/main/generated/librosa.feature.spectral_centroid.html#librosa.feature.spectral_centroid), que utilizaremos para comprobar el resultado.\n\n La formulá para obtener el espectrograma de la trama `l` es:\n \n $centroid[l] = \\frac{\\sum_{k=0}^{Nfft / 2} S[k, l] * f[k]}{\\sum_{k=0}^{Nfft / 2} S[k, l]}$\n\n Fíjese que el centroide espectral es un vector de tamaño igual al número de tramas que hay en el espectograma. \n\n NOTAS de implementación:\n\n * Debe programar la función anterior sin realizar ningún bucle, aprovechando el broadcasting de python y la función `np.sum()`\n * La matriz del espectrograma podría tener alguna columna a cero (silencio total durante una trama). En ese caso tendriamos una indeterminación en la ecuación anterior. Este tipo de situaciones se resuelven en la práctica añadiendo un valor insignificante al denominador. Por ejemplo: `eps = 1e-10`. \n\n\n","metadata":{}},{"cell_type":"code","source":"def spectral_centroid(S,f):\n    \"\"\" Arguments:\n        S: Espectrogram (complex matrix obtained using stft)\n        f: frequencies vector, vectorf with the corresponding frequency of each row of S\n        Returns:\n           Vector with the spectral centroid for all frames\n\n        NOTE: use of librosa.feature.spectral_centroid is not allowed\n    \"\"\"\n    eps = 1e-10\n    S = abs(S) # Tomamos valor absoluto\n\n    numerador = np.sum(S*f[:, None], axis=0)\n    denominador = np.sum(S, axis=0) + eps\n    \n    sc = numerador/denominador # Guarde aqui el vector centroide espectral\n    \n    return sc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Comprobacion \nmy_logger.test(\"spectral centroid\")\n# Calculamos el vector de frecuencias con librosa\nsc_rosa = librosa.feature.spectral_centroid(S = np.abs(S), n_fft=n_fft, sr = fs, window=window)\nsc_rosa = sc_rosa.flatten() # librosa devuelve vector fila en lugar de vector 1D\n\n# Calculamos el vector de frecuencias de la fft\nf = librosa.core.fft_frequencies(n_fft=n_fft, sr = fs)\n# Podiamos obtener alternativamente f de esta forma\n# f = np.arange(nn_fft // 2 +1) / nn_fft * fs\n\nsc = spectral_centroid(S, f)\n\nassert f.shape[0] == 257, \"dimensiones incorrectas de f\"\nassert np.abs(sc_rosa - sc).sum() == pytest.approx(0, abs = 1e-2), \"resultado no coincide con librosa\"\n\n\nt = np.arange(sc.shape[0])* hop_length / fs # Mira como genero t \n\nplt.plot(t,sc)\nplt.plot(t,sc_rosa.flatten())\nplt.xlabel('time')\nplt.title('Spectral centroid')\nplt.ylabel('Hz')\n\nmy_logger.success(\"spectral centroid\",2.0)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ejercicio 2: Calculo del  spectral flux\n\nEl spectral flux es otra característica que se extrae a partir del espectrograma lineal. \n\nEl resultado es un vector con tantos elementos como tramas tiene el espectrograma. Para calcularlo se emplea la siguiente ecuación:\n\n$flux[l] = \\sum_{k=0}^{Nfft / 2} |S[k, l] - S[k, l-1]|^2$\n\nTeniendo en cuenta que:\n* flux[0] = 0\n* S es el valor absoluto del espectrograma: `S = np.abs(S)`\n\nTeniendo en cuenta esto complete la siguiente función:\n","metadata":{}},{"cell_type":"code","source":"def spectral_flux(S):\n    S = np.abs(S) # nos aseguramos de tomar la magnitud\n    \n    flux = np.zeros(S.shape[1])\n\n    #diferencia de cada trama consecutiva\n    diff = S[:, 1:] - S[:, :-1]\n\n    #\n    flux[1:] = np.sum(diff**2, axis=0)\n    \n    return flux","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# comprobacion \nmy_logger.test(\"spectral flux\")\nsf = spectral_flux(S)\n\nassert sf.shape[0] == 35, \"compruebe la función\"\nassert sf[0] == 0.0, \"el primer elemento debe ser cero\"\nassert sf[10] == pytest.approx(1143.53, 1e-2)\n\n\nt = np.arange(sc.shape[0])* hop_length / fs # Mira como genero t \n\nplt.plot(t,sf)\nplt.xlabel('time')\nplt.title('Spectral flux')\nplt.ylabel('Hz')\nmy_logger.success(\"spectral flux\",2.0)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Otras características\nLas tres funciones siguientes se necesitarán para extraer el vector de características. \n\nPuede encontrar las fórmulas que se han utilizado en este [enlace](https://es.mathworks.com/help/audio/ug/spectral-descriptors.html)\n\nFijese que muchas de ellas pueden reutlizar tanto el espectrograma `S` como el vector de frecuencias `f`, además otras funciones pueden reutilizar tanto el `spectral_centroid` si ya lo tiene calculado como el `spectral_spread`.\n\n","metadata":{}},{"cell_type":"code","source":"def spectral_spread(S, f, centroid = None):\n    S = np.abs(S)\n    eps = 1e-10\n    if centroid is None:\n        centroid = spectral_centroid(S,f)\n\n    centroid = centroid.reshape(1,-1)\n    f = f.reshape(-1,1)\n    \n    desv_f = (f - centroid)**2\n\n    spread = np.sqrt((desv_f * S).sum(axis=0) / (S.sum(axis=0)+eps))\n    return spread\n\ndef spectral_skewness(S,f, centroid = None, spread = None):\n    S = np.abs(S)\n    eps = 1e-10\n    if centroid is None:\n        centroid = spectral_centroid(S,f)\n\n    if spread is None:\n        spread = spectral_spread(S,f,centroid=centroid)\n\n    centroid = centroid.reshape(1,-1)\n    f = f.reshape(-1,1)\n \n    desv_f = f - centroid\n\n    num = ((desv_f ** 3)*S).sum(axis=0)\n    den = spread**3 * (S.sum(axis=0))\n    return num / (den + eps)\n\ndef spectral_kurtosis(S,f, centroid = None, spread = None):\n    S = np.abs(S)\n    eps = 1e-10\n    if centroid is None:\n        centroid = spectral_centroid(S,f)\n\n    if spread is None:\n        spread = spectral_spread(S,f,centroid=centroid)\n\n    centroid = centroid.reshape(1,-1)\n    f = f.reshape(-1,1)\n \n    desv_f = f - centroid\n\n    num = ((desv_f ** 4)*S).sum(axis=0)\n    den = spread**4 * (S.sum(axis=0))\n    return num / (den + eps)\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ejercicio 3: Cálculo de los MFCC (Mel Frequency Cepstral Coeficients\n\nLos MFCC se obtienen a partir del espectrograma mel. Los pasos a seguir son los siguientes:\n1. Tomar el `log10` del valor absoluto del espectrograma mel\n2. Calcular la transformada del coseno de cada una de las columnas de la matriz anterior (el resultado es una matriz). Para ello emplearemos la funcion [`scipy.fft.dct`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.dct.html)\n3. Quedarnos con las `n_cepstral` filas de la matriz anterior.\n\nComenzaremos calculando el especrograma mel. En la práctica anterior obteniamos el espectrograma mel a partir de las muestras de la señal. Pero dado que el espectrograma mel se obtiene a partir del espectrograma lineal que hemos empleado para calcular todas las características de los ejercicios anteriores, vamos a obtener el espectrograma mel a partir de la matrix `S` que ya tenemos:\n","metadata":{}},{"cell_type":"code","source":"Smel = librosa.feature.melspectrogram(S= np.abs(S) ,sr=fs,  n_fft=n_fft, \n                                      hop_length=hop_length, \n                                      win_length=win_length,n_mels = 40,\n                                      window=\"hamming\") # reutilizamos el espectrograma lineal","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import scipy \n\ndef calculate_mfcc(Smel, n_cepstral):\n    eps = 1e-10\n    # realice los pasos del enunciado\n    #Tomar log10\n    log_Smel = np.log10(np.abs(Smel)+ eps) \n    \n    #Calcular dct de cada columna (axis = 0)\n\n    mfcc_full = scipy.fft.dct(log_Smel, type=2, axis=0, norm=None)\n\n    #Seleccionar las 13 primeras filas\n    mfcc = mfcc_full[:13, :]\n\n    return mfcc ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Comprobacion \nmy_logger.test(\"mfcc\")\nmfcc = calculate_mfcc(Smel, 13)\nlibrosa.display.specshow(mfcc)\nassert mfcc.shape == (13,35), \"comprueba la funcion\" \nassert mfcc[3,3] == pytest.approx(4.4443, abs=1e-3)\nmy_logger.success(\"mfcc\",2.0)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El resultado obtenido con nuestra función no es exactamente igual al obtenido con la libreria `librosa` por un factor de escala que se produce al tomar el logaritmo. Este factor no es importante en la práctica ya que no cambia la información obtenida. \n\nPodemos comprobar como descartando dicho factor, el aspecto de MFCC obtenido con `librosa` es idéntico:","metadata":{}},{"cell_type":"code","source":"mfcc_rosa = librosa.feature.mfcc(S = librosa.power_to_db(Smel),   n_mfcc=13)\nlibrosa.display.specshow(mfcc_rosa)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"En adelante emplearemos la función que proporciona `librosa` para el cálculo de los MFCC. ","metadata":{}},{"cell_type":"markdown","source":"## Función para extraer características\n\nA continuación se proporciona el código para extrar las 85 características a partir de un fragmento de voz. \n\nLa función:\n1. Quitara silencios iniciales y finales\n2. Calculara espectrogramas lineal y mel\n3. Extraera las características:\n   * mfcc\n   * mfcc delta\n   * spectral centroid\n   * spectral flux\n   * spectral spread\n   * spectral skewness\n   * spectral spectral_kurtosis\n   * spectral roll-off\n\n","metadata":{}},{"cell_type":"code","source":"def extract_features(audio_data, fs):\n    win_length = round(0.032*fs)\n    hop_length = win_length // 2\n    window = 'hamming'\n    n_fft = 512\n    n_mels = 40\n    n_mfcc=13\n    f = librosa.core.fft_frequencies(n_fft=n_fft, sr = fs)\n\n\n    audio_mask = detect_speech(audio_data, fs)\n    audio_trim = audio_data[np.where(audio_mask)]\n    \n    S = librosa.stft(audio_trim, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window)\n    absS = np.abs(S)\n\n    Smel = librosa.feature.melspectrogram(S= absS ,sr=fs,  n_fft=n_fft, \n                                      hop_length=hop_length, \n                                      win_length=win_length,n_mels = n_mels,\n                                      ) # reutilizamos el espectrograma lineal\n    \n    # Extract MFCCs (Mel-frequency cepstral coefficients)\n    mfcc = librosa.feature.mfcc(S = librosa.power_to_db(Smel), sr=fs,  n_mfcc=n_mfcc)\n\n    \n    # Calculate delta MFCCs\n    \n    mfcc_delta = librosa.feature.delta(mfcc)\n    \n    # Calculate spectral flux\n    flux = spectral_flux(absS)\n\n    # Calculate spectral centroid\n    centroid = spectral_centroid(absS,f)\n\n    # Calculate spectral spread\n    spread = spectral_spread(absS,f,centroid=centroid)\n\n    # Calculate spectral skewness\n    skewness = spectral_skewness(absS,f,centroid=centroid, spread=spread)\n\n    # Calculate spectral kurtosis\n    kurtosis = spectral_kurtosis(absS,f,centroid=centroid, spread=spread)\n\n    # Calculate spectral rolloff point\n    rolloff = librosa.feature.spectral_rolloff(S=absS, sr=fs,  roll_percent=0.85)\n\n    audio_features = {}\n    audio_features['mfcc']=mfcc\n    audio_features['mfcc_delta']=mfcc_delta\n    audio_features['flux']=flux\n    audio_features['centroid']=centroid\n    audio_features['spread']=spread\n    audio_features['skewness']=skewness\n    audio_features['kurtosis']=kurtosis\n    audio_features['rolloff']=rolloff\n\n    audio_features = vectorize_features(audio_features)\n    \n    return audio_features\n\n\ndef vectorize_features(audio_features):\n    #13 features\n    avg_mfcc = np.mean(audio_features['mfcc'],axis=1)\n    #13 features\n    var_mfcc = np.std(audio_features['mfcc'],axis=1)\n    #13 features\n    max_mfcc = np.max(audio_features['mfcc'],axis=1)\n    #13 features\n    min_mfcc = np.min(audio_features['mfcc'],axis=1)\n    #13 features\n    avg_mfcc_delta = np.mean(audio_features['mfcc_delta'],axis=1)\n    #13 features\n    var_mfcc_delta = np.std(audio_features['mfcc_delta'],axis=1)\n\n    #2 features\n    avg_flux = np.mean(audio_features['flux'])\n    var_flux = np.std(audio_features['flux'])\n\n    #5 feature\n    avg_centroid = np.mean(audio_features['centroid'])\n    avg_spread = np.mean(audio_features['spread'])\n    avg_skewness = np.mean(audio_features['skewness'])\n    avg_kurtosis = np.mean(audio_features['kurtosis'])\n    avg_rolloff = np.mean(audio_features['rolloff'])\n\n                    \n\n    return np.concatenate([avg_mfcc, var_mfcc, \n                           max_mfcc, min_mfcc, \n                           avg_mfcc_delta, var_mfcc_delta,\n                           [avg_flux, var_flux],\n                           [avg_centroid, avg_spread, avg_skewness, avg_kurtosis, avg_rolloff]])\n                           \n\nA continuación vemos como extraer las caracteristicas, a partir de las muestras de un audio:","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features = extract_features(nine,fs)\nplt.plot(features)\nplt.xlabel('Feature')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"En la figura anterior podemos ver el aspecto de las 85 características que emplearemos en la siguiente práctica para clasificar los audios. \n\nEs importante destacar que el margen dinámico es muy diferente entre las diferentes características, por lo que el primer paso que realizaremos en la siguiente práctica será normalizar estos valores para que se encuentren en rangos dinámicos similares.","metadata":{}}]}